{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8JJwVXZ3QjR2KNBXhUnkf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahadikprasad15/ARENA/blob/main/Steering_on_GPT2_small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJnAzr3lWq_X"
      },
      "outputs": [],
      "source": [
        "%pip install transformer_lens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformer_lens\n",
        "import torch\n",
        "import plotly.express as px\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "gzJ7oasIXj9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = transformer_lens.HookedTransformer.from_pretrained('gpt2-small')\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "-bdLbwnyXj6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers = model.cfg.n_layers\n",
        "heads = model.cfg.n_heads"
      ],
      "metadata": {
        "id": "ny4xaMfYXj4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,love_cache = model.run_with_cache( 'Love')\n",
        "_,hate_cache = model.run_with_cache( 'Hate')"
      ],
      "metadata": {
        "id": "2uS1qvi6Xj1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, I want to take a prompt and steer it using the difference between the love and hate activation vectors, and do it first for a random layer, head, and then systematically for all of them.\n",
        "\n",
        "First we want some baseline, and then change, and plot that for all the heads - and we'll get a list of heads that are important\n",
        "\n"
      ],
      "metadata": {
        "id": "-s-Q_VxtY-zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'I went to the football match because'"
      ],
      "metadata": {
        "id": "F4_Cm2udYbLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_tokens = model.to_tokens(prompt)\n",
        "num_tokens = 10\n",
        "\n",
        "def autoregressive_generator(prompt_tokens, num_tokens):\n",
        "\n",
        "  for n in range(num_tokens):\n",
        "    final_token_pred = model(prompt_tokens).argmax(dim = -1)[:, -1]\n",
        "    prompt_tokens = torch.cat([prompt_tokens, final_token_pred.unsqueeze(0)], dim = -1)\n",
        "\n",
        "  return prompt_tokens"
      ],
      "metadata": {
        "id": "fzrhUvY5YrwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to_string(autoregressive_generator(prompt_tokens, 5))"
      ],
      "metadata": {
        "id": "hDRZQ-tlhYOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, I now know how to generate the few tokens. This can be used in run_with_hooks.\n",
        "So, now I need to get an activation from a head, add it to the same head as hook intervention and keep generating output of that for a few tokens.\n",
        "\n",
        "Output of the run_with_hooks will have logits, we just take argmax for the last position, add it to the prompt and keep doing it for a few tokens."
      ],
      "metadata": {
        "id": "7DaAchpRck84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "love_activation_full = love_cache['blocks.5.hook_resid_post']\n",
        "hate_activation_full = hate_cache['blocks.5.hook_resid_post']\n",
        "\n",
        "# Extract the activation for the last token from each before subtraction\n",
        "love_last_token_activation = love_activation_full[:, -1, :]\n",
        "hate_last_token_activation = hate_activation_full[:, -1, :]\n",
        "\n",
        "# Calculate the difference for steering\n",
        "steering_activation = love_last_token_activation - hate_last_token_activation\n",
        "steering_activation = steering_activation.squeeze(0) # Remove the batch dimension if present"
      ],
      "metadata": {
        "id": "I4DEHJBPZ73j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = 5"
      ],
      "metadata": {
        "id": "F1tOWv-5Z039"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hook_function(activation, hook, alpha):\n",
        "  activation[:, -1] += alpha * steering_activation"
      ],
      "metadata": {
        "id": "tuQSxc_vZ5ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hook functions for different intensities\n",
        "\n",
        "alpha_1 = partial(hook_function, alpha = 1)\n",
        "alpha_2 = partial(hook_function, alpha = 2)\n",
        "alpha_10 = partial(hook_function, alpha = 10)"
      ],
      "metadata": {
        "id": "7wKDC4INldWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Steering different layers\n",
        "\n",
        "def steered_layers(original_prompt_tokens, hook_function = hook_function, num_tokens = 5):\n",
        "\n",
        "  prompt_list = []\n",
        "  for layer in range(layers):\n",
        "    print(f'Steering layer {layer}')\n",
        "    current_prompt_tokens = original_prompt_tokens.clone()\n",
        "\n",
        "    for n in range(num_tokens):\n",
        "\n",
        "      logits_steered = model.run_with_hooks(\n",
        "          current_prompt_tokens,\n",
        "          fwd_hooks = [(transformer_lens.utils.get_act_name('resid_post',layer), hook_function)]\n",
        "      )\n",
        "      next_token = logits_steered[:, -1].argmax(dim = -1).unsqueeze(0)\n",
        "      current_prompt_tokens = torch.cat([current_prompt_tokens, next_token], dim = -1)\n",
        "\n",
        "    prompt_list.append(model.to_string(current_prompt_tokens))\n",
        "\n",
        "  return prompt_list"
      ],
      "metadata": {
        "id": "N5lg4Xv6ahEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Steering with high intensity\n",
        "\n",
        "results_10 = steered_layers(prompt_tokens, alpha_10)"
      ],
      "metadata": {
        "id": "KIl7Q2ijaqN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results of high intensity steering\n",
        "results_1"
      ],
      "metadata": {
        "id": "vTSoq54Ha1Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Steering with medium intensity\n",
        "\n",
        "results_2 = steered_layers(prompt_tokens, alpha_2)"
      ],
      "metadata": {
        "id": "iZ9QALfmg6xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results of medium intensity\n",
        "results_2"
      ],
      "metadata": {
        "id": "joX77JNDg7NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bRspNVSKmLjX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}